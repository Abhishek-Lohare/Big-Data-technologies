{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "sc = pyspark.SparkContext(appName = 'wordcount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySpark Hive connect example\")\\\n",
    ".config(\"spark.sql.warehouse.dir\",\"hdfs://localhost:54310/user/hive/warehouse\")\\\n",
    ".enableHiveSupport()\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|       mydb1|\n",
      "|     pyspark|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database mydb1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|       mydb1|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"use mydb1\").show()\n",
    "# src (key INT, value STRING) USING hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark.sql(\"CREATE TABLE student(id int , name string , marks int) \")\n",
    "\n",
    "spark.sql(\"create table student (id int, name string , marks int) row format delimited  fields terminated by '\\t'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----------+\n",
      "|database|    tableName|isTemporary|\n",
      "+--------+-------------+-----------+\n",
      "|   mydb1|customers_tsv|      false|\n",
      "|   mydb1| products_tsv|      false|\n",
      "|   mydb1|      student|      false|\n",
      "+--------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"load data local inpath '/home/hduser/Desktop/stud' into table student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------------+--------------+----------------+\n",
      "|customer_id|   customer_name|customer_city|customer_state|customer_zipcode|\n",
      "+-----------+----------------+-------------+--------------+----------------+\n",
      "|      11039|     Mary Torres|       Caguas|            PR|             725|\n",
      "|       5623|      Jose Haley|     Columbus|            OH|           43207|\n",
      "|       5829|      Mary Smith|      Houston|            TX|           77015|\n",
      "|       6336|  Richard Maddox|       Caguas|            PR|             725|\n",
      "|       1708|  Margaret Booth|    Arlington|            TX|           76010|\n",
      "|      10227|  Mary Henderson|       Caguas|            PR|             725|\n",
      "|        839|     Lisa Walker|       Caguas|            PR|             725|\n",
      "|       7604|   Jonathan Hill|      Phoenix|            AZ|           85040|\n",
      "|       6485|Carolyn Sheppard|Pompano Beach|            FL|           33063|\n",
      "|       4737|    Mary Mendoza|       Caguas|            PR|             725|\n",
      "|       5973|   Michael Smith|       Caguas|            PR|             725|\n",
      "|       9205|    James Holmes|     Hilliard|            OH|           43026|\n",
      "|        138|     Mary Dawson|       Caguas|            PR|             725|\n",
      "|        371|    Adam Marquez|  San Antonio|            TX|           78223|\n",
      "|       9285|    Gloria Smith|       Caguas|            PR|             725|\n",
      "|       1209|       Mary Webb|   San Marcos|            TX|           78666|\n",
      "|       3021|  Nancy Alvarado|     Flushing|            NY|           11354|\n",
      "|       3354|  Russell Flores|       Caguas|            PR|             725|\n",
      "|      11684|    Denise Smith|    Rego Park|            NY|           11374|\n",
      "|      11144|  Jose Dickerson|         Mesa|            AZ|           85201|\n",
      "+-----------+----------------+-------------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from customers_tsv\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "| id|name|marks|\n",
      "+---+----+-----+\n",
      "| 20|abhi|   95|\n",
      "+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from student where name = 'abhi'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
